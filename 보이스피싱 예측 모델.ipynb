{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lsmlub99/AI-project/blob/main/%EC%BA%A1%EC%8A%A4%ED%86%A4_%EB%AA%A8%EB%8D%B8%EC%82%AC%EC%9A%A9%ED%95%B4%EC%84%9C_%EC%A0%95%ED%99%95%EB%8F%84_1%EB%B2%88_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-v6ILx0Xtda"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qY9KhiYya4oc",
        "outputId": "55ab1913-cdfc-4f21-9f04-ee68a307d5de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.10/dist-packages (3.10.0)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install SpeechRecognition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44L_iM7Na5mH"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0cbw5DX7a5p0"
      },
      "outputs": [],
      "source": [
        "import speech_recognition as sr\n",
        "import os\n",
        "import csv\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1OjBSAzhGX4",
        "outputId": "8d0d0f71-50a9-4713-c9ff-ae3ecc94c47f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuXB6eYwa5tf"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3JGQ_12La5w1"
      },
      "outputs": [],
      "source": [
        "# 음성 파일이 있는 디렉토리 경로 설정\n",
        "sound_dir = \"/content/drive/MyDrive/soundfile/\"\n",
        "r = sr.Recognizer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cofoO8-La50C"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_VmctFRa-X1"
      },
      "outputs": [],
      "source": [
        "# CSV 파일 경로\n",
        "csv_file = \"/content/drive/MyDrive/123.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9MdFhWia-vs"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIsC70oVGnpC",
        "outputId": "1dcd9f02-6142-47d3-a3a4-8a6d88486189"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CSV 파일이 생성되었습니다.\n",
            "                                                                           Text  Label\n",
            "           일단 잘 알겠고요 저희들이 KB 금융 결제 KB 저축은행 인데요 지금 5월 달에 저희들이 대환 대출 플러스 생활 유지 자금      1\n",
            "            대출 상품 있어요 예 그리고 예원이 유리 7.8% 진흥 하는 부분이고 상환기간이 오늘까지 고요 중도상환 가능하고 수수료를      1\n",
            "    발생이 없이 원리금균등분할상환 혹은 만기시 이상한 쪽으로 이자만 바꾸셔도 되는 부분이에요 예 그리고 최대의 BMC 대환대출 플러스 생활      1\n",
            "                        기장 쪽으로 5천만 원까지 이제 5천만 원금도 다 받으실 거예요 일단 잘 알겠고요 정 땡땡 맞으시죠      0\n",
            "                      혹시 카톡을 사용하고 계세요 그러면은요 카톡 추가를 해서 저희들 회사 상황하고 저희는 넣어 드릴게요 예      0\n",
            "왜냐면 저희 쪽 같은 경우에는 신용대출이 아니시고 정부지원금이세요 작품 이름이 서민금융나들목이라고 하시고요 그래서 최대한 도금이 매한 자금으로      1\n",
            "               일단 고객님께서 지금 기존에 쓰고 있는 대출 자금 어디에서 얼마 정도 받고 있으세요 다시 한번 확인 좀 부탁드릴게요      1\n",
            "                                            아니면 이제 좀 봐 주시고요 제가 5분 뒤에 다시 연락 드릴까요      0\n",
            "                            네 그래서 이제 거기 있는게 대략적으로 얼마 정도 남아 있는지 말씀해 주시면 더 좋으신 거죠      1\n",
            "                                                  네 고객님 박찬호입니다 어느 부분에 연락 주신 건가요      0\n"
          ]
        }
      ],
      "source": [
        "target_words = [\"대출\", \"상환\", \"자금\", \"납부\", \"금액\",\n",
        "                \"금리\", \"심사\", \"은행\", \"조사\", \"피해자\",\n",
        "                \"명의\", \"수사\", \"불법\", \"녹취\", \"진술\",\n",
        "                \"검거\", \"본인\", \"통장\", \"말씀\", \"사건\", \"계좌\"]\n",
        "\n",
        "# CSV 파일 열기 및 헤더 작성\n",
        "with open(csv_file, \"w\", newline=\"\") as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"Text\", \"Label\"])\n",
        "\n",
        "    # 음성 파일 순회 및 텍스트 변환\n",
        "    for file_name in os.listdir(sound_dir):\n",
        "        if file_name.endswith(\".wav\"):\n",
        "            file_path = os.path.join(sound_dir, file_name)\n",
        "            with sr.AudioFile(file_path) as source:\n",
        "                audio = r.record(source)\n",
        "            try:\n",
        "                text = r.recognize_google(audio, language='ko')\n",
        "\n",
        "                # 특정 단어가 포함된 경우 레이블 1로 추가\n",
        "                label = 1 if any(word in text for word in target_words) else 0\n",
        "                writer.writerow([text, label])\n",
        "\n",
        "            except sr.UnknownValueError:\n",
        "                print(\"Google Speech Recognition could not understand audio\")\n",
        "            except sr.RequestError as e:\n",
        "                print(\"Could not request results from Google Speech Recognition service; {0}\".format(e))\n",
        "\n",
        "print(\"CSV 파일이 생성되었습니다.\")\n",
        "# CSV 파일 상위 행 수\n",
        "num_rows = 10\n",
        "\n",
        "# CSV 파일 상위 행 출력\n",
        "data = pd.read_csv(csv_file)\n",
        "head_data = data.head(num_rows)\n",
        "print(head_data.to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uQyBvm9GoUz"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1mj-3XmSqWW",
        "outputId": "1f9cb4f2-e002-4051-a668-3c7f846cd563"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.29.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.22.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install torch\n",
        "!pip install pandas\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p62-Oay5Sp-X"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PBVLofxORNKC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gV4gEYTOROTU"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ea5uG0jSROd1"
      },
      "outputs": [],
      "source": [
        "# 데이터 로드\n",
        "data = pd.read_csv('/content/drive/MyDrive/123.csv', usecols=['Text', 'Label'])\n",
        "texts = data['Text'].tolist()\n",
        "texts = data['Text'].tolist()\n",
        "labels = data['Label'].tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yx-pKkl3ROir"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0evnPyN7ROs8"
      },
      "outputs": [],
      "source": [
        "# 전처리 및 토큰화\n",
        "tokenizer = AutoTokenizer.from_pretrained('kykim/bert-kor-base')\n",
        "tokens = tokenizer.batch_encode_plus(\n",
        "    texts,\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "input_ids = tokens['input_ids']\n",
        "attention_mask = tokens['attention_mask']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PfzxomDROwB"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-xX5Jm2ROzB",
        "outputId": "902479ab-7b38-44c9-849c-2b20dbd1c249"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at kykim/bert-kor-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(42000, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 모델 로드\n",
        "model = AutoModelForSequenceClassification.from_pretrained('kykim/bert-kor-base')\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDBtgVwXRO2P"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oFY8a-eARO5E"
      },
      "outputs": [],
      "source": [
        "# 데이터셋 및 데이터로더 생성\n",
        "dataset = torch.utils.data.TensorDataset(input_ids, attention_mask)\n",
        "dataloader = DataLoader(dataset, batch_size=32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kj0mGt_zRO8E"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Phw2-VioRO-7"
      },
      "outputs": [],
      "source": [
        "# 모델 예측\n",
        "predictions = []\n",
        "probabilities = []\n",
        "for batch in dataloader:\n",
        "    batch = [item.to(device) for item in batch]\n",
        "    input_ids, attention_mask = batch\n",
        "    outputs = model(input_ids, attention_mask=attention_mask)\n",
        "    logits = outputs.logits\n",
        "    batch_probabilities = torch.softmax(logits, dim=1)\n",
        "    batch_predictions = torch.argmax(batch_probabilities, dim=1)\n",
        "    probabilities.extend(batch_probabilities[:, 1].tolist())  # 스팸으로 분류될 확률만 추출\n",
        "    predictions.extend(batch_predictions.tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8CqHIcDRPB8"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwqBl4vwRPE4",
        "outputId": "73f0f19f-217f-4c3d-f893-22b748859576"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Text: 일단 잘 알겠고요 저희들이 KB 금융 결제 KB 저축은행 인데요 지금 5월 달에 저희들이 대환 대출 플러스 생활 유지 자금\n",
            "Label: 1\n",
            "Prediction: 1\n",
            "Spam Probability: 0.6214705109596252\n",
            "---\n",
            "Text: 대출 상품 있어요 예 그리고 예원이 유리 7.8% 진흥 하는 부분이고 상환기간이 오늘까지 고요 중도상환 가능하고 수수료를\n",
            "Label: 1\n",
            "Prediction: 1\n",
            "Spam Probability: 0.5809612274169922\n",
            "---\n",
            "Text: 발생이 없이 원리금균등분할상환 혹은 만기시 이상한 쪽으로 이자만 바꾸셔도 되는 부분이에요 예 그리고 최대의 BMC 대환대출 플러스 생활\n",
            "Label: 1\n",
            "Prediction: 1\n",
            "Spam Probability: 0.5821889638900757\n",
            "---\n",
            "Text: 기장 쪽으로 5천만 원까지 이제 5천만 원금도 다 받으실 거예요 일단 잘 알겠고요 정 땡땡 맞으시죠\n",
            "Label: 0\n",
            "Prediction: 1\n",
            "Spam Probability: 0.6275591850280762\n",
            "---\n",
            "Text: 혹시 카톡을 사용하고 계세요 그러면은요 카톡 추가를 해서 저희들 회사 상황하고 저희는 넣어 드릴게요 예\n",
            "Label: 0\n",
            "Prediction: 0\n",
            "Spam Probability: 0.4776182174682617\n",
            "---\n",
            "Text: 왜냐면 저희 쪽 같은 경우에는 신용대출이 아니시고 정부지원금이세요 작품 이름이 서민금융나들목이라고 하시고요 그래서 최대한 도금이 매한 자금으로\n",
            "Label: 1\n",
            "Prediction: 1\n",
            "Spam Probability: 0.60178142786026\n",
            "---\n",
            "Text: 일단 고객님께서 지금 기존에 쓰고 있는 대출 자금 어디에서 얼마 정도 받고 있으세요 다시 한번 확인 좀 부탁드릴게요\n",
            "Label: 1\n",
            "Prediction: 0\n",
            "Spam Probability: 0.49291136860847473\n",
            "---\n",
            "Text: 아니면 이제 좀 봐 주시고요 제가 5분 뒤에 다시 연락 드릴까요\n",
            "Label: 0\n",
            "Prediction: 1\n",
            "Spam Probability: 0.5040486454963684\n",
            "---\n",
            "Text: 네 그래서 이제 거기 있는게 대략적으로 얼마 정도 남아 있는지 말씀해 주시면 더 좋으신 거죠\n",
            "Label: 1\n",
            "Prediction: 1\n",
            "Spam Probability: 0.5018640756607056\n",
            "---\n",
            "Text: 네 고객님 박찬호입니다 어느 부분에 연락 주신 건가요\n",
            "Label: 0\n",
            "Prediction: 1\n",
            "Spam Probability: 0.5296758413314819\n",
            "---\n",
            "Text: 고객님이 동네 지점이 여러 군데 있어요 맞으시죠\n",
            "Label: 0\n",
            "Prediction: 0\n",
            "Spam Probability: 0.4839431941509247\n",
            "---\n",
            "Text: 혹시 영업 1팀으로 연락 주신 거 맞으세요 잠실 지점 이제 저희가 지점이\n",
            "Label: 0\n",
            "Prediction: 0\n",
            "Spam Probability: 0.4929221570491791\n",
            "---\n",
            "Text: 크다 보니까 기본적으로 이제 1층 일반 부서에서는 저희 대출팀 직원을 모르실 수도 있어요 예 대출\n",
            "Label: 1\n",
            "Prediction: 1\n",
            "Spam Probability: 0.5345013737678528\n",
            "---\n",
            "Text: 영업 대주 1팀으로 연락을 하셔서 확인해 보시면 이제 다 확인이다 되시는 부분 2시고요 예\n",
            "Label: 0\n",
            "Prediction: 0\n",
            "Spam Probability: 0.4566793143749237\n",
            "---\n",
            "Text: 내일 저기 캐피탈 심사 결과 확인 되어서 연락 드리고 어떻게 통화 가능하신가요\n",
            "Label: 1\n",
            "Prediction: 0\n",
            "Spam Probability: 0.46596574783325195\n",
            "---\n",
            "Text: 일단 결과는 확인은 다 되셨는데 지금 보면은 이게 조금 어렵다고 전달을 받았어요\n",
            "Label: 0\n",
            "Prediction: 1\n",
            "Spam Probability: 0.5013598799705505\n",
            "---\n",
            "Text: 사유를 정확하게 확인을 좀 해 보니까 기존에 저희를 알아보시기 전에\n",
            "Label: 0\n",
            "Prediction: 0\n",
            "Spam Probability: 0.448078989982605\n",
            "---\n",
            "Text: 이게 금융사 여러군데 반복적으로 점수가 되셨거나 지원해 주신 이력들이 사이 쉬면서 지금 시험 평점 자체가 너무 떨어졌더라구요\n",
            "Label: 0\n",
            "Prediction: 0\n",
            "Spam Probability: 0.4613306224346161\n",
            "---\n",
            "Text: 미리 말을 맞춰 놓고 진행하는 대출이다 대출자금을 100% 가능한 대출이나 해서 제가 설명을 드리는 거고요\n",
            "Label: 1\n",
            "Prediction: 0\n",
            "Spam Probability: 0.4450095593929291\n",
            "---\n",
            "Text: 아 예 저 지금고 그 쪽에서 그 공문 확인해서 연락 드린 건데 그 쪽에서는 저희 쪽으로 안내해 주셨어요 고객님\n",
            "Label: 0\n",
            "Prediction: 0\n",
            "Spam Probability: 0.4821922779083252\n",
            "---\n",
            "Text: 현재 진행하시는 대출의 상품은 신용대출은 아니고 이제 소득 담보대출이란 그래서 연체를 하실경우 나 고의적인 상하네 피해가 있으실 경우\n",
            "Label: 1\n",
            "Prediction: 0\n",
            "Spam Probability: 0.4550202488899231\n",
            "---\n",
            "Text: 자윙 처리 비용 발생 되시는 금액 같은 경우에는 이제 실제 소모 되시는 수수료는 아니기 때문에 정상승인 한두 결과가 나오시면 100% 환급 처리해드립니다 다만\n",
            "Label: 1\n",
            "Prediction: 1\n",
            "Spam Probability: 0.6126803755760193\n",
            "---\n",
            "Text: 그건 이제 등록하고 뭐 여쭤 봐야 되죠 지금 다짜고짜 50 오면 어떡합니까 고객님 지금 신분증 접수도 안 해 줬는데 그냥 그쪽으로 면접 하면 어떡합니까\n",
            "Label: 0\n",
            "Prediction: 1\n",
            "Spam Probability: 0.5385921597480774\n",
            "---\n",
            "Text: 네 알겠습니다 제가 점심 시간 이후에 때쯤 다시 한번 전화 드리겠습니다\n",
            "Label: 0\n",
            "Prediction: 1\n",
            "Spam Probability: 0.5236397981643677\n",
            "---\n",
            "Text: 지금 실제 거주하시는 지역이 울산이세요 울산 심사 절정 일을 바로 진행 도와 드리겠습니다\n",
            "Label: 1\n",
            "Prediction: 0\n",
            "Spam Probability: 0.45113494992256165\n",
            "---\n",
            "Text: 상환이 않으셨다구요 어디가 상황이 안 드셨다는 거죠 고객센터에서 알아보신 건가요\n",
            "Label: 1\n",
            "Prediction: 0\n",
            "Spam Probability: 0.4146696925163269\n",
            "---\n",
            "Text: 목요일 날 성환 하신 거 말씀하시는 거죠 그게 지금 고객 센터로 넘어가는게 좀 서류가 늦게 들어가서 확인이 안 되실 수도 있으세요\n",
            "Label: 1\n",
            "Prediction: 1\n",
            "Spam Probability: 0.5094640254974365\n",
            "---\n",
            "Text: 그쪽에서 기록 삭제를 하고 고객님과 4 하셨잖아요 납부가 어렵잖아요 그쪽도 전산망으로 이제 고객 센터에 보내야 돼요 서류를\n",
            "Label: 1\n",
            "Prediction: 1\n",
            "Spam Probability: 0.5029276609420776\n",
            "---\n",
            "Text: 그래가지고 그게 아마 밀리 저거 갖고 와 이렇게 밀리지 않았고 오늘까지 안 되시면 월요일 쯤에 아마 그쪽에서 고객센터 확인이 가능하신 부분이에요\n",
            "Label: 0\n",
            "Prediction: 0\n",
            "Spam Probability: 0.3446861803531647\n",
            "---\n",
            "Text: 아 예 안녕하세요 저희 그 하나캐피탈\n",
            "Label: 0\n",
            "Prediction: 1\n",
            "Spam Probability: 0.5508608818054199\n",
            "---\n",
            "Text: 예 예 지금 보시면은 그 이제 신용 등급은 하고는 관계 없이 저희 측에서\n",
            "Label: 0\n",
            "Prediction: 1\n",
            "Spam Probability: 0.518379271030426\n",
            "---\n",
            "Text: 지원처 연락을 좀 드린 거고 현재 이용 중이신 고객님 건 어디 어디 이용 중이시죠\n",
            "Label: 0\n",
            "Prediction: 0\n",
            "Spam Probability: 0.4505956768989563\n",
            "---\n",
            "Text: 아네네 알겠습니다 바로 연락 한번 부탁드릴게요네네\n",
            "Label: 0\n",
            "Prediction: 0\n",
            "Spam Probability: 0.4251973032951355\n",
            "---\n",
            "Text: 네 여보세요 아네 고객님 청담동 계셨던 하나 키텔 김민기 대리입니다 아네 고객님 진행 상황에 대해서 어떻게 진행해 도움을 드려야 될까요\n",
            "Label: 0\n",
            "Prediction: 1\n",
            "Spam Probability: 0.6099609136581421\n",
            "---\n",
            "Text: 그 부분에 대해서는 저희 쪽 작은 받아보시고 주말 있으시기 때문에 화요일까지는 납부 처리해 주시고 완납 하셨다는 완납증명서 저희 집으로 보내 주셔야 하시고요\n",
            "Label: 1\n",
            "Prediction: 0\n",
            "Spam Probability: 0.48187151551246643\n",
            "---\n",
            "Text: 일단 저랑 통화 중에 계셔 가지고 본인인지 안내부터 도움을 드릴 건데 본인이 사용하는 핸드폰이 본인 맞으십니까\n",
            "Label: 1\n",
            "Prediction: 0\n",
            "Spam Probability: 0.48451492190361023\n",
            "---\n",
            "Text: 네이버 검색 나는 본인 숫자로 1 2 3 4 1 2 2 1 1 8\n",
            "Label: 1\n",
            "Prediction: 0\n",
            "Spam Probability: 0.45471224188804626\n",
            "---\n",
            "Text: 네 그러시면 검색 그 아래 주소로 클릭해 입력하시면 웹 페이지로 이동하시겠습니까 URL 바로 가기를 클릭해 주시고요\n",
            "Label: 0\n",
            "Prediction: 1\n",
            "Spam Probability: 0.5189823508262634\n",
            "---\n",
            "Text: 현재 저희가 고객님 앞으로 최대 1200만원까지 이용 가능하시다고 문자 보내 드렸네요 지금 신청하시면 반응 하시고요\n",
            "Label: 0\n",
            "Prediction: 1\n",
            "Spam Probability: 0.5559829473495483\n",
            "---\n",
            "Text: 아네 그러시면 이용 방법은 똑같은 시고요 한도와 이용 같은 경우에는요 고객님의 신용등급에 따라 조금씩 차등이 될 수 있고요\n",
            "Label: 0\n",
            "Prediction: 1\n",
            "Spam Probability: 0.5249162912368774\n",
            "---\n",
            "Text: 기존에 사용하시던 통장과 저희가 연동시켜 드려서 기존 통장이 마이너스통장으로 이용이 가능하게끔 해드립니다\n",
            "Label: 1\n",
            "Prediction: 0\n",
            "Spam Probability: 0.4661411941051483\n",
            "---\n",
            "Text: 그게 무슨 말씀이신가요 고객님께서 저축 은행에서 대출금 받으신게 있으시다구요 아 그럼 고객 사용금액이 마이너스가 표시가 되신 건가요\n",
            "Label: 1\n",
            "Prediction: 1\n",
            "Spam Probability: 0.5953183174133301\n",
            "---\n"
          ]
        }
      ],
      "source": [
        "# 결과 출력\n",
        "for text, label, prediction, probability in zip(texts, labels, predictions, probabilities):\n",
        "    print('Text:', text)\n",
        "    print('Label:', label)\n",
        "    print('Prediction:', prediction)\n",
        "    print('Spam Probability:', probability)\n",
        "    print('---')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEuRIcmrRPII"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMF/CzoMlo4B3LF+XjXS+ZS",
      "include_colab_link": true,
      "mount_file_id": "1jl5J7QtZ74bDE6KL_TBRaXLlI5ohdM_G",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
